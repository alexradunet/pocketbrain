# Local LLM override for e2e tests — adds Ollama, no cloud API key required for the agent.
#
# Usage (layered on top of docker-compose.e2e.yml):
#   docker compose -f docker-compose.e2e.yml -f docker-compose.e2e.local.yml \
#     up --build --exit-code-from e2e-runner --abort-on-container-exit
#
# Or via npm script:
#   bun run e2e:local
#
# The agent (pocketbrain-e2e) uses qwen2.5:3b via Ollama.
# llmAssert() is NOT used — the local runner targets src/e2e/infra.test.ts only
# (infrastructure tests with no AI-quality assertions).
#
# Smallest model options (set OLLAMA_MODEL env var to override):
#   qwen2.5:1.5b  — 0.98 GB, marginal tool calling, fastest
#   qwen2.5:3b    — 1.90 GB, reliable responses     (default)
#   qwen2.5-coder:7b — 4.5 GB, best small option

services:
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama-models:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:11434/api/tags"]
      interval: 5s
      timeout: 5s
      retries: 12
      start_period: 10s

  # One-shot init container: pulls the model then exits 0.
  # pocketbrain-e2e waits for this to complete before starting.
  # On warm runs the model is already cached in the ollama-models volume — exits in <5s.
  ollama-init:
    image: ollama/ollama:latest
    restart: "no"
    volumes:
      - ollama-models:/root/.ollama
    environment:
      OLLAMA_HOST: "http://ollama:11434"
    entrypoint: ["ollama", "pull"]
    command: ["${OLLAMA_MODEL:-qwen2.5:3b}"]
    depends_on:
      ollama:
        condition: service_healthy

  pocketbrain-e2e:
    environment:
      OPENCODE_MODEL: "ollama/${OLLAMA_MODEL:-qwen2.5:3b}"
      OPENCODE_BASE_URL: "http://ollama:11434/v1"
      # Ollama ignores the API key but OpenCode requires a non-empty value
      OPENCODE_API_KEY: "ollama"
    depends_on:
      ollama-init:
        condition: service_completed_successfully

  # Override runner to target infra tests only (no llmAssert, no ANTHROPIC_API_KEY needed)
  e2e-runner:
    command: >
      sh -lc "bun install --frozen-lockfile &&
      bun test src/e2e/infra.test.ts"

volumes:
  ollama-models:
    # Persist downloaded models across runs to avoid re-downloading.
    # To reset: bun run e2e:local:down  (passes -v flag to remove volume)
