# ğŸŒ³ Level 3 â€” Senior / Architect Guide

> **Who this is for:** A senior engineer or system designer who wants to
> understand *why* PocketBrain is built the way it is â€” the tradeoffs,
> constraints, and design principles behind every major decision.
> Assumes you've read [ğŸŒ¿ Level 2](./GUIDE_INTERMEDIATE.md).
> See the [emoji legend](./GUIDE.md#ï¸âƒ£-emoji-concept-legend) for visual anchors.

---

## ğŸ’¡ Core Architectural Thesis

PocketBrain is built on a single principle: **complexity is the enemy of
security and understandability**. Every design decision traces back to this.

The project exists as a reaction to OpenClaw/ClawBot â€” a system that grew
to 52+ modules, 8 config management files, 45+ dependencies, and application-
level permission checks trying to prevent agents from accessing things they
shouldn't. The complexity made it impossible to audit, understand, or trust.

PocketBrain's answer: **fewer moving parts, stronger boundaries**.

---

## ğŸ—ï¸ Macro Architecture: Why a Single Process?

### The Alternative
A naive design would run each agent invocation in its own process (or
container), with a message broker (Redis, RabbitMQ) between the ğŸ’¬ WhatsApp
receiver and ğŸ§  agent runners. This is what OpenClaw does.

### ğŸ’¡ Why PocketBrain Doesn't

**1. Complexity scales with components.** Every additional process boundary
adds serialization, network calls, failure modes, and debugging surface.
A message broker has its own operations burden. One process eliminates all of this.

**2. The ğŸ³ container IS the sandbox.** The security argument for per-invocation
containers (isolate each agent run) is compelling, but Docker-in-Docker is
operationally painful. Instead, PocketBrain runs ONE container that provides
OS-level isolation. Agents run with full power inside, sandboxed from the host.

**3. ğŸ—„ï¸ SQLite is sufficient.** SQLite in WAL mode handles the read-write
patterns here easily â€” one writer (message loop), multiple readers (scheduler,
IPC watcher). No connection pooling required.

**4. Shared memory is fine at this scale.** State is small (hundreds of
messages, tens of sessions). A global in-memory `Map` for active ğŸ”„ sessions
is far simpler than distributed state.

> âš ï¸ **Tradeoff accepted:** Single-process means a crash takes down everything.
> Acceptable for a personal-use tool â€” Docker's `restart: unless-stopped`
> handles it. All durable state is in ğŸ—„ï¸ SQLite and files.

---

## ğŸ“ The IPC Design: Why Files?

### The Problem
The ğŸ§  AI agent (running inside OpenCode SDK) needs to trigger side effects on
the host â€” send ğŸ’¬ WhatsApp messages, create â° scheduled tasks, register ğŸ‘¥ groups.
How does the agent communicate with the host process?

### Options Considered

| Option | Problem |
|--------|---------|
| Shared memory | Only works within one process |
| Unix sockets | Requires connection management, auth |
| HTTP to host | Port conflicts, adds a server to the host |
| ğŸ“ File-based IPC | Simple, atomic, no connections, no auth tokens |

### ğŸ’¡ Why Files Won

**âš¡ Atomicity via `rename`.** A file write is not atomic â€” a reader might see
a half-written file. But `rename()` is atomic on POSIX filesystems. The ğŸ”Œ MCP
server writes to `.json.tmp`, then renames to `.json`. The ğŸ“ IPC watcher only
processes `.json` files, so it never sees partial writes.

**ğŸ›¡ï¸ Identity from path, not content.** The ğŸ“ IPC watcher determines ğŸ‘¥ group
identity from the **directory** the file was written to
(`data/ipc/main/tasks/`) â€” not from what the file claims. This prevents
privilege escalation: an agent cannot forge a different group identity by
writing a JSON field.

**ğŸ” Durability across restarts.** If the process crashes between the agent
writing a file and the watcher processing it, the file survives. On restart,
the watcher processes it.

> âš ï¸ **Tradeoff accepted:** 1-second poll latency on IPC (acceptable for
> messaging). Startup cleanup needed for orphaned `.json.tmp` files.

---

## ğŸ”„ Session Management Design

### The Problem
OpenCode SDK sessions have a context window. Long conversations cause the
session to "compact" â€” summarize old content to free context. After
compaction, information the ğŸ§  agent needs (ğŸ‘¥ group identity, chatJid, etc.)
may be lost.

### ğŸ’¡ The Solution: Context Re-injection

Every prompt sent to the agent â€” **including follow-ups** â€” prepends a
`<pocketbrain_context>` XML block:

```typescript
function buildContextPrefix(group, input): string {
  return `<pocketbrain_context>
chatJid: ${input.chatJid}
groupFolder: ${input.groupFolder}
isMain: ${input.isMain}
...
</pocketbrain_context>`;
}
```

This is **stateless** from the host's perspective â€” it doesn't matter whether
the agent remembers the context from before compaction, because the host
re-injects it every time.

> âš ï¸ **Tradeoff:** Slightly larger prompt on every follow-up. Negligible in
> practice (< 200 characters).

### ğŸ”„ Session Persistence

Session IDs are stored in ğŸ—„ï¸ SQLite (`sessions` table). On restart, all
sessions are loaded and resumed on the next message. The OpenCode SDK server
recreates session state from its own store.

This gives conversational continuity across process restarts without the
host storing full conversation history.

---

## ğŸ”€ GroupQueue: Concurrency Design

### The Problem
Multiple ğŸ‘¥ WhatsApp groups can receive ğŸ’¬ messages simultaneously. Each group
needs its own ğŸ§  agent session. But running unlimited concurrent sessions would
exhaust memory, overload the OpenCode server, and hit API rate limits.

### ğŸ’¡ The Design

`GroupQueue` implements a **two-level** concurrency model:

**Level 1: Per-group exclusivity.** Only one ğŸ”„ session runs per ğŸ‘¥ group at
a time. Messages for an active group are buffered (`pendingMessages = true`)
and processed immediately after the current session ends. This ensures
message ordering within a group.

**Level 2: Global cap.** `MAX_CONCURRENT_SESSIONS` (default: 5) limits total
concurrent sessions. ğŸ‘¥ Groups beyond the cap join `waitingGroups` (FIFO).
When a session completes, the next waiting group gets a slot.

**Priority:** â° Scheduled tasks are drained before pending ğŸ’¬ messages within
a group. Rationale: tasks are enqueued with specific timing and shouldn't
wait behind an interactive session indefinitely.

**ğŸ” Retry with exponential backoff:** Agent failures are retried up to 5
times with delays of 5s, 10s, 20s, 40s, 80s. After 5 failures, messages
are dropped with a warning (they'll retry on the next incoming message).

> âš ï¸ **Tradeoff:** Message ordering is strictly preserved within a group.
> This is correct behavior for a chat assistant. The global cap is a
> configuration knob to tune for available memory/API quotas.

---

## ğŸ›¡ï¸ Security Architecture

### The Threat Model

| Threat | Mitigation |
|--------|-----------|
| Malicious user in a ğŸ‘¥ group | Non-main groups cannot control other groups; ğŸ¯ trigger required |
| Prompt injection via ğŸ’¬ messages | XML-escaped message content; agent output filtered |
| Agent exceeds its authority | ğŸ“ IPC authorization from directory identity, not agent claims |
| ğŸ³ Container escape | Not in scope (Docker security boundary) |
| Host credential leak | WhatsApp auth never mounted in agent context |

### ğŸ’¡ Why Container Isolation > Application Permissions

OpenClaw tried to prevent agents from accessing files via allowlists and
permission checks in application code. This is inherently fragile â€” a clever
prompt might find an indirect path to restricted operations.

PocketBrain takes the opposite approach: the agent **can** do anything in
the ğŸ³ container, and the container **cannot** do anything to the host beyond
the explicit volume mount. There's no permission check to bypass; the OS
enforces the boundary.

> âš ï¸ **Tradeoff accepted:** The agent can modify anything in `/workspace`.
> This is acceptable â€” the user chose to give the agent access to that
> directory, just as they'd choose what to put in a shared folder with a
> trusted collaborator.

### ğŸ›¡ï¸ IPC Authorization Layers

```
ğŸ§  Agent (inside OpenCode)
  â”‚
  â”‚ writes JSON to data/ipc/{sourceGroup}/tasks/
  â”‚
ğŸ“ IPC Watcher
  â”‚
  â”œâ”€ Identity: sourceGroup = directory name (ğŸ›¡ï¸ OS-enforced, not agent-claimed)
  â”‚
  â”œâ”€ isMain = (sourceGroup === MAIN_GROUP_FOLDER)
  â”‚
  â””â”€ Authorization table:
      schedule_task:  targetFolder === sourceGroup OR isMain
      cancel_task:    task.group_folder === sourceGroup OR isMain
      register_group: isMain only ğŸ‘‘
      refresh_groups: isMain only ğŸ‘‘
```

**Path traversal defense** in the ğŸ”Œ MCP server:
```typescript
function safeFolder(folder: string): string {
  const sanitized = path.basename(folder);  // strips any ../../..
  if (!sanitized || sanitized === '.' || sanitized === '..') throw ...;
  return sanitized;
}
```
`path.basename()` extracts only the last path component, so
`../../etc/passwd` becomes `passwd` which fails to match any group directory.

---

## ğŸ”„ The Two-Timestamp Cursor System

### Why Two Cursors?

```
Timeline of ğŸ’¬ messages in a group:
  [msg1][msg2][msg3][msg4][msg5][msg6]
                â†‘                 â†‘
    lastAgentTimestamp       lastTimestamp
    (ğŸ§  agent processed        (ğŸ’¬ WhatsApp saw
      up to here)               up to here)
```

**`lastTimestamp`** (global): Advances immediately when any new ğŸ’¬ messages
are seen. Prevents re-processing in the poll loop.

**`lastAgentTimestamp[groupJid]`** (per-group): Advances only after the ğŸ§ 
agent successfully processes a batch. The "pending context"
(`msg4, msg5, msg6` in the example) accumulates between ğŸ¯ trigger invocations
and is included in full when the next trigger arrives.

**ğŸ” The cursor rollback pattern:**
- Agent fails **before** any output â†’ `lastAgentTimestamp` rolls back â†’ ğŸ” retry
- Agent fails **after** sending output â†’ cursor **not** rolled back (no duplicates)

> ğŸ’¡ This is a deliberate "at-most-once retry after user sees output" guarantee.

---

## ğŸ“¡ OpenCode SDK Integration Pattern

### Server Lifecycle

The OpenCode server is embedded in-process via `createOpencode()`. It runs
an HTTP server on `127.0.0.1:4096` (localhost only). This is not a remote
API call â€” it's an in-process server that the SDK starts. ğŸ§ 

### ğŸ“¡ SSE Streaming vs Final Fetch

Response collection has two layers for resilience:

**Layer 1 (ğŸ“¡ SSE stream):** Real-time `message.part.updated` deltas accumulate
text as the model generates. When `session.idle` fires, streaming stops.

**Layer 2 (âœ… canonical fetch):** After streaming, `client.session.message()`
fetches the canonical final message state. Handles cases where the SSE
stream was interrupted or delivered out-of-order events.

```typescript
const canonicalText = extractTextFromParts(messageRespData?.parts ?? []);
const streamedText = joinTextParts(textParts, textPartOrder);
const fullText = canonicalText || streamedText;  // âœ… canonical wins
```

**â³ Timeouts:**

| Operation | Timeout | Rationale |
|-----------|---------|-----------|
| Session create/resume | 15s | Hangs would block a ğŸ‘¥ group indefinitely |
| Prompt stream | 120s | Long ğŸ§  agent runs need time |
| Canonical fetch | 30s | Final safety net |

### ğŸ”Œ MCP Server as Child Process

The ğŸ”Œ MCP server (`src/mcp-tools.ts`) runs as a **stdio** child process of the
OpenCode server. Why stdio?
- No ports, no authentication
- Process lifecycle tied to the parent
- When OpenCode terminates, the ğŸ”Œ MCP server terminates automatically

---

## ğŸ§© The Skills Architecture

### Design Problem
Every user wants different integrations (Telegram, Gmail, Slack). Adding all
of them to the core codebase creates bloat. But a plugin system adds
complexity.

### ğŸ’¡ The Solution: Code Transformation Skills

Instead of a plugin system, PocketBrain uses OpenCode's native ğŸ§© skills system.
A skill is a `SKILL.md` file containing instructions for the ğŸ§  AI agent to
modify the codebase. When a user runs `/add-telegram`, the agent:

1. Reads the SKILL.md instructions ğŸ“
2. Modifies `src/channels/` to add a Telegram channel ğŸ’¬
3. Updates `src/index.ts` to register the new channel ğŸ”„
4. Runs tests âœ…

The user ends up with **clean code** that does exactly what they need â€” no
dead code for features they don't use, no conditional branching for different
providers.

> âš ï¸ **Tradeoff:** Skills are one-directional â€” they add/replace code. There's
> no version management. Fine for a personal-use project where you fork and
> own the code.

---

## ğŸ”Œ Extension Points

If you're planning to extend PocketBrain, here are the designed surfaces:

### ğŸ’¬ Adding a New Channel

1. Implement the `Channel` interface (`src/types.ts:46`):
   ```typescript
   interface Channel {
     name: string;
     connect(): Promise<void>;
     sendMessage(jid: string, text: string): Promise<void>;
     isConnected(): boolean;
     ownsJid(jid: string): boolean;  // ğŸ”€ routes by JID pattern
     disconnect(): Promise<void>;
     setTyping?(jid: string, isTyping: boolean): Promise<void>;
   }
   ```
2. Call `connect()` in `main()` and add to `channels[]`
3. The router (`src/router.ts:39`) selects the right channel by `ownsJid()`

### ğŸ”Œ Adding New MCP Tools

Add `server.tool(...)` calls in `src/mcp-tools.ts`. The tool is immediately
available to the ğŸ§  agent. Follow the ğŸ“ IPC file pattern for operations that
need the host process.

### ğŸ“ Adding New IPC Operations

Add a new `case` in `src/ipc.ts:processTaskIpc()`. Always check `isMain`
and `sourceGroup` against ğŸ›¡ï¸ authorization requirements.

### ğŸ§  Changing the AI Model

Set `OPENCODE_MODEL` and `OPENCODE_API_KEY` in `.env`. The model is passed
through `createOpencode()` config. OpenCode SDK is model-agnostic.

---

## ğŸš« What's NOT in PocketBrain (Intentionally)

| Feature | Why It's Absent |
|---------|----------------|
| Message broker (Redis/RabbitMQ) | Adds operational complexity for no functional gain |
| WebSocket/HTTP API server | No external consumers; ğŸ“ IPC is sufficient |
| Config management system | Code changes are cleaner than config files |
| Plugin registry | ğŸ§© Skills do the same thing without a plugin runtime |
| Per-invocation containers | ğŸ³ Container IS the sandbox; re-spawning adds latency |
| Multi-user auth | Built for one user; YAGNI |
| Monitoring dashboard | Ask the ğŸ§  AI ("what's in the logs?") |
| Admin UI | ğŸ‘‘ Main WhatsApp group IS the admin UI |

---

## âš¡ Performance Characteristics

| Operation | Latency | Notes |
|-----------|---------|-------|
| ğŸ’¬ Message detection | ~2s | Poll interval |
| ğŸ“ IPC processing | ~1s | Poll interval |
| ğŸ”„ Session creation | ~1-3s | Network + SDK init |
| ğŸ“¡ First token from model | 2-10s | Model dependent |
| ğŸ§  Full response (simple) | 5-30s | Task complexity |
| â° Scheduled task detection | ~60s | Scheduler poll |

> ğŸ’¡ The system is optimized for **correctness and simplicity** over low
> latency. A 2-second poll is fine for a conversational assistant.

---

## âš ï¸ Known Constraints and Future Work

**Context window pressure:** Long conversations eventually trigger OpenCode's
compaction. The `pocketbrain_context` re-injection handles this, but
very long-running sessions may lose non-injected context. Per-group ğŸ“
`AGENTS.md` files help keep important context durable.

**No delivery receipts:** WhatsApp delivery/read receipts are not tracked.
The system sends ğŸ’¬ and moves on.

**Single ğŸ§  LLM endpoint:** All ğŸ‘¥ groups share one OpenCode SDK instance.
Different models per group would require multiple instances.

**â° Scheduled task drift:** `interval` tasks are anchored to the previous
`next_run` (not wall clock) to prevent drift. `cron` tasks always compute
from the expression. `once` tasks are one-shot.

---

*Back to [ğŸ—ºï¸ Guide Index](./GUIDE.md)*
